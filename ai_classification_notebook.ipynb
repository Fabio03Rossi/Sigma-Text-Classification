{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## SetFit Few-Shot Classification\n",
    "\n",
    "In questo notebook vengono mostrati i segmenti di codice e i procedimenti eseguiti per effettuare l'allenamento e l'inferenza del modello di classificazione.\n",
    "\n",
    "L'obiettivo è quello di classificare le note di chiusura degli interventi dei tecnici in base alle aree di guasto possibili della macchina. Queste comprendono: CASSETTE, CT, NE, NF, NV e SHUTTER.\n",
    "Il sistema deve poter categorizzare questi elementi testuali in maniera più o meno affidabile attraverso IA, includendo anche più di un'area per selezione.\n",
    "\n",
    "La task che quindi dobbiamo eseguire si ricongiunge ad una classificazione di testo multi-label.\n",
    "\n",
    "L'approccio utilizzato per la risoluzione consiste nel Few-Shot Learning, dove un modello IA di embedding viene allenato su un numero N di esempi reali per ogni singola label. Richiede più tempo e risorse hardware ma permette di ottenere risultati migliori in ambienti con pochi dati di allenamento e somprattutto categorizzazioni complesse come nel nostro caso.\n",
    "\n",
    "Utilizziamo diverse librerie di HuggingFace come Sentence-Transformers e SetFit per la definizione e l'allenamento del modello IA, insieme a Datasets per la manipolazione dei dati necessari agli step di training, validation e test.\n",
    "\n",
    "\n",
    "\n",
    "Qui di seguito nella prima cella definiamo la variabile d'ambiente per poter utilizzare la GPU durante l'allenamento.\n"
   ],
   "id": "642499842ae4ad7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:41:14.156372Z",
     "start_time": "2025-07-02T11:41:14.141303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ],
   "id": "6f4ffbdf154b7448",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Come primo step andiamo ad importare i 3 dataset necessari a completare l'operazione di training.\n",
    "Consistono nel dataset di training che presenta una varietà di dati labellizzati su cui il modello eseguirà l'allenamento, poi c'è il dataset di validation che contiene altri elementi labellizzati e conosciuti per validare l'accuratezza del modello in casi controllati.\n",
    "Infine abbiamo il dataset di test, contenente una grande collezione di note di chiusura senza labellizzazioni revisionate in cui il modello verrà messo contro le selezioni dei tecnici.\n",
    "\n",
    "I dataset sono estratti in pandas Dataframe da dei file Excel, e successivamente convertiti in Dataset filtrando le colonne ritenute non rilevanti per l'allenamento.\n",
    "\n",
    "Le label vengono estratte dalle colonne del dataset di training nel formato \"{label} ground-truth\"."
   ],
   "id": "2721eae5908503c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:41:17.058684Z",
     "start_time": "2025-07-02T11:41:14.173099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "df_training = pd.read_excel(\"path-del-set-di-training\")\n",
    "df_validation = pd.read_excel(\"path-del-set-di-validation\")\n",
    "df_test = pd.read_excel(\"path-del-set-di-test\")\n",
    "\n",
    "dataset = Dataset.from_pandas(df_training.iloc[:, 9:16])\n",
    "validation_dataset = Dataset.from_pandas(df_validation.iloc[:, 9:16])\n",
    "test_dataset = Dataset.from_pandas(df_test.iloc[:, [0,1,2,3,4,5, 32, 49]])\n",
    "\n",
    "features = dataset.column_names\n",
    "features.remove(\"Closing Note\")\n",
    "features"
   ],
   "id": "fa00cdd568c331c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CASSETTE ground-truth',\n",
       " 'CT ground-truth',\n",
       " 'NE ground-truth',\n",
       " 'NF ground-truth',\n",
       " 'NV ground-truth',\n",
       " 'SHUTTER ground-truth']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Eseguiamo ulteriori elaborazioni sui nostri dataset correnti, in cui rimappiamo le colonne delle singole label in una singola colonna \"labels\" contenente un vettore delle singole selezioni in formato binario.\n",
    "\n",
    "Successivamente rimuoviamo tutte le righe in cui le note di chiusura risultano vuote."
   ],
   "id": "dc44987fb900d8fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:41:18.651659Z",
     "start_time": "2025-07-02T11:41:17.068402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = dataset.map(lambda entry: {\"labels\": [entry[label] for label in features]})\n",
    "validation_dataset = validation_dataset.map(lambda entry: {\"labels\": [entry[label] for label in features]})\n",
    "validation_dataset = validation_dataset.map(lambda entry: {\"text\": entry[\"Closing Note\"]})\n",
    "test_dataset = test_dataset.map(lambda entry: {\"labels\": [entry[label] for label in features]})\n",
    "test_dataset = test_dataset.map(lambda entry: {\"text\": entry[\"Closing Note\"]})"
   ],
   "id": "eb63af081b970b50",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fbrossi\\PyCharmMiscProject\\.venv1\\Lib\\site-packages\\datasets\\utils\\_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n",
      "Map: 100%|██████████| 118/118 [00:00<00:00, 5948.72 examples/s]\n",
      "Map: 100%|██████████| 50/50 [00:00<00:00, 2247.00 examples/s]\n",
      "Map: 100%|██████████| 50/50 [00:00<00:00, 7709.55 examples/s]\n",
      "Map: 100%|██████████| 4453/4453 [00:00<00:00, 8711.91 examples/s]\n",
      "Map: 100%|██████████| 4453/4453 [00:00<00:00, 4466.50 examples/s]\n"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:41:18.910147Z",
     "start_time": "2025-07-02T11:41:18.673428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dictionary = {\"text\": dataset[\"Closing Note\"], \"labels\": dataset['labels']}\n",
    "train_dataset = Dataset.from_dict(dictionary)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataset.to_pandas().dropna())\n",
    "train_dataset = Dataset.from_pandas(train_dataset.to_pandas().replace(r'^\\s*$', \"Empty\", regex=True))\n",
    "\n",
    "dictionary = {\"text\": validation_dataset[\"Closing Note\"], \"labels\": validation_dataset['labels']}\n",
    "validation_dataset = Dataset.from_dict(dictionary)\n",
    "\n",
    "validation_dataset = Dataset.from_pandas(validation_dataset.to_pandas().dropna())\n",
    "validation_dataset = Dataset.from_pandas(validation_dataset.to_pandas().replace(r'^\\s*$', \"Empty\", regex=True))\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_dataset.to_pandas().dropna())\n",
    "test_dataset = Dataset.from_pandas(test_dataset.to_pandas().replace(r'^\\s*$', \"Empty\", regex=True))"
   ],
   "id": "dfc07251f0b8c2d1",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "get_templated_dataset è un metodo di SetFit che permette di generare dati sintetici a seconda delle necessità.\n",
    "Date le label e impostando il parametro multi_label = True, possiamo decidere un numero di esempi sintetici che verranno aggiunti per label seguendo un template uguale per tutte. Risulta essere molto semplice e modificabile, ma aiuta comunque per la classificazione."
   ],
   "id": "7bf04a1f3cf44a76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:41:19.045154Z",
     "start_time": "2025-07-02T11:41:18.926351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from setfit import get_templated_dataset\n",
    "\n",
    "train_dataset = get_templated_dataset(train_dataset, candidate_labels=features, sample_size=5, label_column=\"labels\", multi_label=True, template=\"Il problema è del {}\")"
   ],
   "id": "527bcfc7845b3820",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Si definisce una funzione per l'inizializzazione del modello che verrà usato dal trainer.\n",
    "Vi è anche la possibilità di passare direttamente la variabile del modello, ma la funzione è vantaggiosa per motivi di versatilità, e la possibilità di implementare alcune funzionalità aggiuntive che la richiedono.\n",
    "\n",
    "Qui definiamo delle parametrizzazioni di base tra cui:\n",
    "    - la temperatura (rappresenta la creatività del modello ed è impostata a 0);\n",
    "    - il numero, e la lista di label con cui deve rispondere;\n",
    "    - la strategia di selezione della label (nel nostro caso \"multi-output\", ma anche \"one-vs-rest\"...)."
   ],
   "id": "1dc964b55c6a627b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:41:22.380418Z",
     "start_time": "2025-07-02T11:41:19.072154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from setfit import SetFitModel\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "def model_init(params):\n",
    "    params = {\"device\": torch.device(\"cuda\"), 'out_features': 6, 'temperature': 0}\n",
    "    return SetFitModel.from_pretrained(\"BAAI/bge-small-en-v1.5\",\n",
    "                                       multi_target_strategy=\"multi-output\", params=params, labels=features)"
   ],
   "id": "86905f293e33e283",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Successivamente specifichiamo nel dettaglio i parametri a cui il nostro Trainer sarà sottoposto, questo significa che ogni elemento che si definisce qui riguarderà la fase di allenamento e non sarà quindi necessario ridefinirle in qualsiasi altro utlizzo del modello post-allenamento.\n",
    "\n",
    "Qui è anche possibile specificare dei parametri per il debugging.\n",
    "\n",
    "Gli elementi che più interessano in questo caso sono: <br>\n",
    "    <p>- <b>body_learning_rate</b> (definisce \"quanto\" il modello dovrà imparare ad ogni step dell'allenamento. Se troppo alto rischia di causare più facilmente \"over-training\");</p>\n",
    "    <p>- <b>num_epochs</b> (rappresenta il numero di volte che il dataset viene attraversato nella sua interezza);</p>\n",
    "    <p>- <b>batch_size</b> (il numero di sample processato per ogni step, un \"chunk\");</p>\n",
    "    <p>- <b>warmup_proportion</b> (influisce sul learning_rate nei primi step di allenamento, mantenendo un basso valore prima di passare al learning_rate definito. Dovrebbe aiutare ad aumentare l'attenzione del modello);</p>\n",
    "    <p>- <b>sampling_strategy</b> (riguarda il bilanciamento del numero di comparazioni per label. \"unique\" in questo caso non bilancia il peso delle label, garantendo comunque che vengano effettuate tutte le comparazioni senza duplicazioni).</p>"
   ],
   "id": "c1c68a049213b81a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:41:22.412090Z",
     "start_time": "2025-07-02T11:41:22.388219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from setfit import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    # Parametri di training opzionali:\n",
    "    body_learning_rate=1.9859376752033417e-05,\n",
    "    num_epochs=2,\n",
    "    batch_size=6,\n",
    "    warmup_proportion=0.2,\n",
    "    sampling_strategy=\"unique\",\n",
    "    # Parametri di debugging:\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1000,\n",
    "    eval_strategy=\"steps\",\n",
    "    logging_first_step=True,\n",
    "    eval_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    run_name=\"finetune-setfit\",\n",
    "    load_best_model_at_end=True\n",
    ")"
   ],
   "id": "6f1d2efa4f612c85",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Si inizializza poi il Trainer specificando i dataset di training e validation, gli argomenti e la funzione di inizializzazione del modello precedentemente definiti, cominciando lo step di Fine-Tuning.",
   "id": "5849fd1084c6193a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:41:26.889381Z",
     "start_time": "2025-07-02T11:41:22.469164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from setfit import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    column_mapping={\"text\": \"text\", \"labels\": \"label\"},\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "id": "5b6ff5c58687a721",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to the training dataset\n",
      "Applying column mapping to the evaluation dataset\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "C:\\Users\\fbrossi\\PyCharmMiscProject\\.venv1\\Lib\\site-packages\\datasets\\utils\\_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n",
      "Map: 100%|██████████| 148/148 [00:00<00:00, 10686.12 examples/s]\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Si verifica l'accuratezza generale del modello allenato con una semplice metrica, contro il set di validation.",
   "id": "2b63f681cbdc126b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:41:26.955437Z",
     "start_time": "2025-07-02T11:41:26.950322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ],
   "id": "5a784cfa7b412071",
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sono definite alcune funzioni utili per la manipolazione dei risultati.",
   "id": "ff9fe5de2fc7236c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:41:28.019438Z",
     "start_time": "2025-07-02T11:41:26.993662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "def export_as_excel(filename, preds, bool):\n",
    "    preds = map(lambda i: i.numpy().astype(numpy.int64).tolist(), preds)\n",
    "    if bool:\n",
    "        df_out = Dataset.to_pandas(test_dataset)\n",
    "    else:\n",
    "        df_out = Dataset.to_pandas(validation_dataset)\n",
    "\n",
    "    print(preds)\n",
    "    print(k.numpy().astype(numpy.int64).tolist() for k in preds)\n",
    "\n",
    "    cassette, ct, ne, nf, nv, shutter = [], [], [], [], [], []\n",
    "\n",
    "\n",
    "    for k in preds:\n",
    "        cassette.append(int(k[0]))\n",
    "        ct.append(int(k[1]))\n",
    "        ne.append(int(k[2]))\n",
    "        nf.append(int(k[3]))\n",
    "        nv.append(int(k[4]))\n",
    "        shutter.append(int(k[5]))\n",
    "\n",
    "    df_out = pd.concat([df_out, pd.DataFrame({\n",
    "                \"CASSETTE Model\": cassette,\n",
    "                \"CT Model\": ct,\n",
    "                \"NE Model\": ne,\n",
    "                \"NF Model\": nf,\n",
    "                \"NV Model\": nv,\n",
    "                \"SHUTTER Model\": shutter\n",
    "    })], axis=1)\n",
    "\n",
    "    df_out = pd.concat([df_out, pd.DataFrame({\n",
    "        \"model_body\": model.model_body\n",
    "    })], axis=0)\n",
    "\n",
    "    df_out.to_excel(filename, index=False)\n",
    "\n",
    "\n",
    "def elaborate_pred(i):\n",
    "    result = []\n",
    "    count = 0\n",
    "    for k in i:\n",
    "        if k == 1:\n",
    "            result.append(str(features[count]))\n",
    "        count += 1\n",
    "    return result\n",
    "\n",
    "def confusion_matrix(w_dataset):\n",
    "    res = multilabel_confusion_matrix(w_dataset['labels'], preds).ravel().tolist()\n",
    "    n = 4\n",
    "    res = [res[i:i + n] for i in range(0, len(res), n)]\n",
    "    res = {\"CASSETTE\": res[0], \"CT\": res[1], \"NE\": res[2], \"NF\": res[3], \"NV\": res[4], \"SHUTTER\": res[5]}\n",
    "    return res\n",
    "\n",
    "def percentage(array):\n",
    "    if not len(array) == 0:\n",
    "        return round((sum(array) / len(array)) * 100, 2)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def print_results(w_dataset):\n",
    "    CASSETTE, CT, NF, NE, NV, SHUTTER, CRM = [], [], [], [], [], [], []\n",
    "    ac_cassette, ac_ct, ac_nf, ac_ne, ac_nv, ac_shutter = [], [], [], [], [], []\n",
    "    ac_cassette_pred, ac_ct_pred, ac_nf_pred, ac_ne_pred, ac_nv_pred, ac_shutter_pred = [], [], [], [], [], []\n",
    "\n",
    "    array = []\n",
    "    count = 0\n",
    "    for i in preds:\n",
    "        i = i.numpy().astype(numpy.int64).tolist()\n",
    "        matching = w_dataset['labels'][count]\n",
    "        print(str(w_dataset['text'][count]) + '\\n' + str(elaborate_pred(matching)) + '\\n' + str(elaborate_pred(i)) + '\\n' + str(pred_proba[count]) + '\\n')\n",
    "        array.append(w_dataset['labels'][count] == i)\n",
    "\n",
    "        ac_cassette.append(matching[0])\n",
    "        ac_cassette_pred.append(i[0])\n",
    "        ac_ct.append(matching[1])\n",
    "        ac_ct_pred.append(i[1])\n",
    "        ac_ne.append(matching[2])\n",
    "        ac_ne_pred.append(i[2])\n",
    "        ac_nf.append(matching[3])\n",
    "        ac_nf_pred.append(i[3])\n",
    "        ac_nv.append(matching[4])\n",
    "        ac_nv_pred.append(i[4])\n",
    "        ac_shutter.append(matching[5])\n",
    "        ac_shutter_pred.append(i[5])\n",
    "\n",
    "        count2 = 0\n",
    "        for k in matching:\n",
    "            truth_selection = k == 1\n",
    "            pred_selection = i[count2] == 1\n",
    "            if truth_selection or pred_selection:\n",
    "                match count2:\n",
    "                    case 0:\n",
    "                        CASSETTE.append(k == i[count2])\n",
    "                    case 1:\n",
    "                        CT.append(k == i[count2])\n",
    "                    case 2:\n",
    "                        NE.append(k == i[count2])\n",
    "                    case 3:\n",
    "                        NF.append(k == i[count2])\n",
    "                    case 4:\n",
    "                        NV.append(k == i[count2])\n",
    "                    case 5:\n",
    "                        SHUTTER.append(k == i[count2])\n",
    "            count2 += 1\n",
    "        count += 1\n",
    "\n",
    "    result = \"Total: \" + str(round(accuracy_score(w_dataset[\"labels\"], preds), 2)) + \" - \" + str(len(array)) + \"\\nCASSETTE: \" + str(round(balanced_accuracy_score(ac_cassette, ac_cassette_pred), 2)) + \" - \" + str(len(CASSETTE)) + \"\\nCT: \" + str(round(balanced_accuracy_score(ac_ct, ac_ct_pred), 2)) + \" - \" + str(len(CT)) + \"\\nNE: \" + str(round(balanced_accuracy_score(ac_ne, ac_ne_pred), 2)) + \" - \" + str(len(NE)) + \"\\nNF: \" + str(round(balanced_accuracy_score(ac_nf, ac_nf_pred), 2)) + \" - \" + str(len(NF)) + \"\\nNV: \" + str(round(balanced_accuracy_score(ac_nv, ac_nv_pred),2)) + \" - \" + str(len(NV)) + \"\\nSHUTTER: \" + str(round(balanced_accuracy_score(ac_shutter, ac_shutter_pred),2)) + \" - \" + str(len(SHUTTER)) + '\\n\\n'\n",
    "    print(str(result))\n",
    "\n",
    "    print(\"TN, FP, FN, TP \\n\")\n",
    "    print(str(confusion_matrix(w_dataset)) + '\\n')"
   ],
   "id": "14e207d0338f0758",
   "outputs": [],
   "execution_count": 140
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A seguito del completamento del Fine-Tuning, si salva il modello su disco in modo tale da poter farne riuso.",
   "id": "5a9513b44dc8def8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = trainer.model\n",
    "model.save_pretrained(\"path-del-modello\")"
   ],
   "id": "d5676bde7dbe95e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Quando si vuole utilizzare un modello esterno già presente su disco ad esempio, basta richiamare l'apposito metodo fornito da SetFitModel con il path e nome del modello.\n",
    "\n",
    "Per eseguire una predizione basta richiamare il metodo predict dal model fornendo la lista di stringhe che si devono testare. In questo caso utilizziamo la colonna \"text\" del dataset di testing che contiene tutte le note dei tecnici.\n",
    "\n",
    "Si può anche utilizzare il metodo predict_proba che fornisce le percentuali di confidenza sulle scelte che il modello ha preso per le predizioni."
   ],
   "id": "3fa512dafc0e92f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = SetFitModel.from_pretrained(\"path-del-modello\")\n",
    "\n",
    "preds = model.predict(test_dataset['text'])\n",
    "pred_proba = model.predict_proba(test_dataset['text'])"
   ],
   "id": "b37510342767aa26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Si va a scrivere le predizioni all'interno di un nuovo file Excel per una più facile consultazione e analisi.",
   "id": "1873ad717484526b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "export_as_excel('ClosingNotesResults.xlsx', preds, False)",
   "id": "96be2276b757e54c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Infine si va a stampare in output ogni singola predizione e le sue probabilità, accodando ai risultati svariati valori di accuratezza tra cui la balanced accuracy di ogni label e la subset accuracy del totale.\n",
    "\n",
    "Si forniscono anche le informazioni di training relative al modello allenato in questo caso, per poi fornire un completo classification report tramite sklearn, approfondendo nel dettaglio molte altre metriche di valutazione che potrebbero risultare rilevanti per ulteriori procedure di tuning."
   ],
   "id": "2fbef059e49448c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print_results(validation_dataset)\n",
    "print(\"body_learning_rate: \" + str(args.body_learning_rate))\n",
    "print(\"num_epochs: \" + str(args.num_epochs))\n",
    "print(\"batch_size: \" + str(args.batch_size))\n",
    "print(\"warmup_proportion: \" + str(args.warmup_proportion))\n",
    "print(classification_report(test_dataset['labels'], preds, target_names=features, zero_division=0))"
   ],
   "id": "ec78d584dc7e4446"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
